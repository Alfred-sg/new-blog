---
title: 数据技术踩点
category:
  - 大数据
tags:
  - 大数据
keywords: '大数据'
abbrlink: d4bcd594
date: 2020-01-18 00:00:00
updated: 2020-01-18 00:00:00
---

数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成的（Integrate）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。

* OLTP：On-Line Transaction Processing，联机事务处理，辅助业务操作，用于产生数据。OLTP 能将源数据即时传送到计算中心进行处理，并在短时间内给出结果。
* OLAP：On-Line Analytical Processing，联机分析处理，辅助决策分析，用于分析数据。
* ETL：Extract-Transform-Load，数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。

![image](sj1.png)

上图为数据仓库架构发展过程中的第二阶段 —— Lambda 架构。第三阶段 Kappa 架构借助 Flink 等实时流处理引擎，移除了离线批处理 etl 任务。数据仓库构架的发展过程可以参看 [数据仓库介绍与实时数仓案例](https://developer.aliyun.com/article/691541)。

* ODS：OperationalData Store，操作数据层，保存从业务系统或埋点系统采集过来的原始数据。
* DWD：Data Warehouse Detail，明细数据层，根据主题定义好事实与维度表，保存最细粒度的事实数据。该层数据的生产作业包含：字段名、枚举等数据标准统一；数据脱敏，专门建设敏感数据库存储敏感数据；分库分表等多源数据整合；数据模型统基于业务流程建模。
* DWS：Data Warehouse Summary，汇总数据层，在 DWD 层基础上根据不同的业务需求分主题轻度汇总。DWS 层可拆分为 DWB 轻度汇总数据和 DWS 重度汇总数据。
* DM：Data Market，数据集市层，主要为业务需求提供服务，其包含应用产品所需数据、需求报表、指标等，DM 层还可为业务部门创建专用数据库以及数据探索库。

下图为阿里大数据系统的架构图：

![image](sj2.jpg)

### 数据同步

数据同步的方式：

* 直连同步：通过 ODBC、JDBC 等标准接口将源系统的数据导入到目标系统，对业务系统的性能影响较大（虽然业务系统可以采用主备分离的模式）。
* 数据文件同步：通过 FTP 服务器将源系统的数据导入到目标系统。为避免丢包或传输错误，业务系统一般还会发送校验文件，并对数据增加压缩和加密功能。
* 数据库日志解析同步：在操作系统层面获取归档日志，将其解析到目标文件数据文件中，可用于增量更新。日志解析同步需要部署一个 agent 系统从源系统抽取数据。该同步机制会导致增量更新的数据丢失调凌晨附近的数据，即数据飘逸和遗漏。

### DataX

阿里内部使用 [DataX](https://github.com/alibaba/DataX) 作离线数据同步。它能实现包括 MySQL、Oracle、SqlServer、Postgre、HDFS、Hive、ADS、HBase、TableStore(OTS)、MaxCompute(ODPS)、DRDS 等各种异构数据源之间高效的数据同步功能。DataX 面对的主要问题是，从源系统到数仓或从数仓到目标系统，数据流进各个系统时的格式并不统一，因此 Datax 需要将数据转换成格式统一的中间状态。

DataX 采用 Framework + Plugin 开放式架构实现。Plugin 用于转换不同数据库或文件系统的数据格式，包含 ReadPlugin、WritePlugin 两类，作为 Reader 数据采集模块和 Writer 数据写入模块的实现内容。Framework 将数据同步作业拆分成多个子任务，并处理缓冲、流程控制、并发、上下文加载等高速数据交换等技术问题，再通过 Chanel 交换 Reader、Writer 的数据。

![image](sj3.jpeg)

更多内容可参考 [DataX3.0 简介](https://blog.csdn.net/u014646662/article/details/82792725)。

### TimeTunnel

阿里内部使用 TimeTunnel 作实时数据同步。它所实现的主要功能包含，通过消息订阅模式从源系统的 binlog 日志读取出增量数据，随后订阅数据的目标系统将读取这些数据。

TimeTunnel 是基于生产者、消费者和 Topic 消息标识实现的消息中间件。它通过 HBase 持久化消息数据。在下图的组件架构中：TTManager 负责对外提供队列申请、删除、查询和集群的管理接⼝；对内发现故障，发起队列迁移。Client 是一组访问接口，包含安全认证 api、发布 api 和订阅 api。Router 为 Client、Broker 提供路由服务，路由到 Broker 时须鉴权。Zookeeper 提供状态同步功能，存储 Client、Broker 的状态。Broker 负责消息队列的读写操作，承担实际的流量，它会从 HBase 取发数据。

![image](sj4.png)

更多内容可参考 [淘宝实时数据传输平台: TimeTunnel介绍](https://blog.csdn.net/pelick/article/details/26265663)。

### 数据计算

收集到原始数据后，数据还需要被整合和计算，才能发挥大数据的商业和业务价值。阿里为数据计算层提供了两大体系：MaxCompute 离线存储及计算平台、StreamCompute 实时计算平台。

### MaxCompute

[MaxCompute](https://helpcdn.aliyun.com/document_detail/27800.html) 采用分布式计算模型，能满足 100GB 以上规模的存储及计算需求。它支持 SQL 查询、UDF 用户自定义函数、Java MapReduce 编程模型、Graph 图计算处理框架。

![image](sj5.png)

MaxCompute 由四部分组成：MaxCompute Client 客户端；MaxCompute Front End 接入层；MaxCompute Server 逻辑层；MaxCompute Core 存储与计算层。其中，客户端提供了 RESTful API、Java SDK、Command Line Tool、为 ETL/BI 提供的可视化 IDE 工具。接入层提供 HTTP 服务、缓存、负载均衡、用户认证等功能。逻辑层负责实现用户空间和对象的管理、命令的解析与执行逻辑、数据对象的访问控制和授权等功能。它有三种角色：Worker 对接 RESTful API、SQL 等，生成 MaxCompute Instance 并交由 Scheduler 处理；Scheduler 负责 MaxCompute Instance 的调度和拆解，询问计算层的资源占用情况；Exector 负责 MaxCompute Instance 的执行，向计算层提交计算任务。计算层即 Apsara Core 飞天内核，运行在和控制层相互独立的计算集群上，它包含 Pangu 分布式文件系统、Fuxi 资源调度系统、Nuwa 命名空间服务、Zhongkui 安全服务、Shennong 监控模块、Open Table Service 开放结构化数据服务（用于存储元数据）等。

![image](sj6.png)

更多内容可参考 [阿里巴巴飞天大数据平台MaxCompute（原名ODPS）全套攻略](https://developer.aliyun.com/article/78108)、[MaxCompute 2.0 生态开放之路及最新发展](https://developer.aliyun.com/article/61529)、[MaxCompute 2.0 性能优化揭秘](https://www.sohu.com/a/129170041_612370)、[MaxCompute，基于Serverless的高可靠大数据服务](https://developer.aliyun.com/article/690510)、[阿里云大数据计算服务 - MaxCompute (原名 ODPS)](https://www.cnblogs.com/barrywxx/p/10739834.html)、[当我们用 MaxCompute 的时候，我们在用什么？](https://www.jianshu.com/p/4104e7d5316f)。

### 实时计算

数据时效性一般分为三种：延迟以天计算的离线数据、延迟以小时计算的准实时数据、延迟以秒计算的实时数据。离线数据和准实时数据都可以在批处理系统（如 Hadoop、MaxCompute、Spark 等系统）中实现；实时数据则需要流处理系统（如 Storm、S4、Spark Streaming、Flink、StreamCompute 等系统）来实现。区别于批处理系统周期性调度任务，流处理系统的任务是常驻的，并需要满足高时效性、高性能的要求。流处理系统不能完全替代批处理系统，因为它的计算成本加大，且需要解决复杂的业务逻辑（数据处理需要上下文关系，数据抵达时间的不确定性导致流处理系统可能获取不到前置数据）。

流处理系统所需要的数据可以通过 TimeTunnel、Kafka 等数据中间件或 MetaQ、Notify 等消息系统实现。其中，使用数据中间件能获得较高的吞吐量，一般用于应对数据量较大的业务系统；消息系统一般用作业务系统数据库变更的消息中转。

下图是 flink 的架构图：

![image](sj7.png)

更多内容可参考 [什么是阿里云实时计算](https://help.aliyun.com/document_detail/110778.html?spm=a2c4g.11186623.6.554.2c6d15eaTRijei)、[Streaming System 第一章：Streaming 101](https://developer.aliyun.com/article/674448)、[Flink架构及其工作原理](https://www.cnblogs.com/code2one/p/10123112.html)。

数据服务
阿里的数据开放服务经历了四个阶段：DWSOA、OpenAPI、SmartDQ 和 OneService。

![image](sj8.jpg)

* DWSOA：烟囱式一个需求一个或者几个接口。
* OpenApi：同类数据（如会员数据）合并成一张逻辑表，对外透出一个接口，通过接口参数定位具体数据。
* SmartDQ：逻辑表的取数据逻辑通过 SQL （作为领域专用语言 DSL）描述，SmartDQ 通过解析 SQL、生成执行计划、执行 SQL、合并数据、限制结果，最终透出数据。
* OneService：在 SmartDQ 基础上，满足不同场景的数据需求，OneService-SmartDQ 简单的查询场景、OneService-Lego 个性化业务场景、 OneService-iPush 实时数据推送场景、OneService-uTiming 定时任务场景。

在 SmartDQ 中，逻辑表通过多个数据源的物理表汇总而成，多个逻辑表挂在一个主题下。服务层主要包含两大模块：元数据配置维护物理表到逻辑表的映射；主处理模块会解析 DSL、构建逻辑 Query、构建物理 Query、拆分 Query、执行 SQL、合并结果。

![image](sj9.png)

### 参考

《大数据之路——阿里巴巴大数据实践》
[数仓](https://www.cnblogs.com/shengyang17/p/10527700.html)
[说说数仓](https://www.jianshu.com/p/da62fb0c6a0b)
[大数据环境下数仓设计](https://blog.51cto.com/abezoo/2399546)